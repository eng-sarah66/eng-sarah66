{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.14",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kaggle": {
      "accelerator": "nvidiaTeslaT4",
      "dataSources": [
        {
          "sourceId": 10183730,
          "sourceType": "datasetVersion",
          "datasetId": 6291033
        }
      ],
      "dockerImageVersionId": 30805,
      "isInternetEnabled": true,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": true
    },
    "colab": {
      "name": "notebook5f99947299",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/eng-sarah66/eng-sarah66/blob/master/notebook5f99947299.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "source": [
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "import kagglehub\n",
        "saraali66_milddementedrgb_pro256_path = kagglehub.dataset_download('saraali66/milddementedrgb-pro256')\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "u0xZDXeD3cKF"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "# This Python 3 environment comes with many helpful analytics libraries installed\n",
        "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
        "# For example, here's several helpful packages to load\n",
        "\n",
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "# Input data files are available in the read-only \"../input/\" directory\n",
        "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
        "\n",
        "import os\n",
        "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
        "    for filename in filenames:\n",
        "        print(os.path.join(dirname, filename))\n",
        "\n",
        "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\"\n",
        "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
      ],
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "id": "-YTxIhp83cKT"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.src.legacy.preprocessing.image import ImageDataGenerator\n",
        "import keras\n",
        "from keras.callbacks import EarlyStopping,ModelCheckpoint\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import classification_report\n",
        "from tqdm import tqdm\n",
        "from imblearn.over_sampling import SMOTE\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import tensorflow.compat.v1 as tf\n",
        "import skimage\n",
        "import skimage.io"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:12:31.752258Z",
          "iopub.execute_input": "2025-01-18T19:12:31.75261Z",
          "iopub.status.idle": "2025-01-18T19:12:44.449469Z",
          "shell.execute_reply.started": "2025-01-18T19:12:31.752578Z",
          "shell.execute_reply": "2025-01-18T19:12:44.448518Z"
        },
        "id": "oSOdCAny3cKV"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/sarah127/Diffusion-GAN.git"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2024-12-12T18:39:38.218365Z",
          "iopub.execute_input": "2024-12-12T18:39:38.21904Z",
          "iopub.status.idle": "2024-12-12T18:39:40.124894Z",
          "shell.execute_reply.started": "2024-12-12T18:39:38.219008Z",
          "shell.execute_reply": "2024-12-12T18:39:40.124031Z"
        },
        "id": "IPblXjGc3cKX"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /kaggle/working/Diffusion-GAN/diffusion-projected-gan"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:12:46.990896Z",
          "iopub.execute_input": "2025-01-18T19:12:46.991517Z",
          "iopub.status.idle": "2025-01-18T19:12:46.999296Z",
          "shell.execute_reply.started": "2025-01-18T19:12:46.991483Z",
          "shell.execute_reply": "2025-01-18T19:12:46.996934Z"
        },
        "id": "lvUxZCRR3cKf",
        "outputId": "4701d6be-7248-4cba-b442-79e05e68a1c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "/kaggle/working/Diffusion-GAN/diffusion-projected-gan\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!pip install timm==0.5.4\n",
        "!pip install ftfy\n",
        "!pip install Ninja\n",
        "!pip install setuptools==59.5.0\n",
        "!pip install torch==1.9.0+cu111 torchvision==0.10.0+cu111 torchaudio==0.9.0 -f https://download.pytorch.org/whl/torch_stable.html"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:12:56.906182Z",
          "iopub.execute_input": "2025-01-18T19:12:56.906487Z",
          "iopub.status.idle": "2025-01-18T19:13:45.340607Z",
          "shell.execute_reply.started": "2025-01-18T19:12:56.906462Z",
          "shell.execute_reply": "2025-01-18T19:13:45.339449Z"
        },
        "id": "5xefuXWD3cKi"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import click\n",
        "import re\n",
        "import json\n",
        "import tempfile\n",
        "import torch\n",
        "import dnnlib\n",
        "import train\n",
        "from training import training_loop\n",
        "from metrics import metric_main\n",
        "from torch_utils import training_stats\n",
        "from torch_utils import custom_ops\n",
        "import legacy"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:15:08.353501Z",
          "iopub.execute_input": "2025-01-18T19:15:08.35386Z",
          "iopub.status.idle": "2025-01-18T19:15:12.021982Z",
          "shell.execute_reply.started": "2025-01-18T19:15:08.353828Z",
          "shell.execute_reply": "2025-01-18T19:15:12.021278Z"
        },
        "id": "eYcN_2B_3cKj"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "os.environ['CUDA_LAUNCH_BLOCKING']=\"1\"\n",
        "os.environ['TORCH_USE_CUDA_DSA'] = \"2\"\n",
        "!set CUDA_LAUNCH_BLOCKING = 1\n",
        "os.environ['TORCH_CUDA_ARCH_LIST']='7.5'\n",
        "!export CUDA_LAUNCH_BLOCKING=1"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:15:15.052328Z",
          "iopub.execute_input": "2025-01-18T19:15:15.052688Z",
          "iopub.status.idle": "2025-01-18T19:15:17.061517Z",
          "shell.execute_reply.started": "2025-01-18T19:15:15.052658Z",
          "shell.execute_reply": "2025-01-18T19:15:17.060429Z"
        },
        "id": "egbcfnqi3cKl",
        "outputId": "0d1e8d40-0133-4e8f-f853-bf0f258809b4"
      },
      "outputs": [
        {
          "name": "stderr",
          "text": "/opt/conda/lib/python3.10/pty.py:89: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n  pid, fd = os.forkpty()\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\""
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:15:22.618794Z",
          "iopub.execute_input": "2025-01-18T19:15:22.619188Z",
          "iopub.status.idle": "2025-01-18T19:15:22.624245Z",
          "shell.execute_reply.started": "2025-01-18T19:15:22.619138Z",
          "shell.execute_reply": "2025-01-18T19:15:22.623281Z"
        },
        "id": "ee_xBUoc3cKn"
      },
      "outputs": [],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/train.py  --outdir=training-runs  --data='/kaggle/input/milddementedrgb-pro256' --gpus=1 --cfg='fastgan' --kimg=3700    --target=0.45 --d_pos='first' --noise_sd=0.5  --batch=16    --resume=\"\"https://huggingface.co/zhendongw/diffusion-gan/resolve/main/checkpoints/diffusion-projectedgan-lsun-church.pkl --snap=5 --seed=0 --restart_every=9999999 --cbase=32768  --cmax=512  --dlr=0.002 --metrics=None\n",
        "#fastgan"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-12T10:20:08.599792Z",
          "iopub.execute_input": "2025-01-12T10:20:08.60045Z",
          "iopub.status.idle": "2025-01-12T11:34:26.79043Z",
          "shell.execute_reply.started": "2025-01-12T10:20:08.600416Z",
          "shell.execute_reply": "2025-01-12T11:34:26.789442Z"
        },
        "id": "3AQ4HY703cKp",
        "outputId": "a4f629c6-0287-4b4f-8a30-6083b7fd6a8c"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "\nTraining options:\n{\n  \"G_kwargs\": {\n    \"class_name\": \"pg_modules.networks_fastgan.Generator\",\n    \"cond\": false,\n    \"synthesis_kwargs\": {\n      \"lite\": false\n    }\n  },\n  \"G_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.0002\n  },\n  \"D_opt_kwargs\": {\n    \"class_name\": \"torch.optim.Adam\",\n    \"betas\": [\n      0,\n      0.99\n    ],\n    \"eps\": 1e-08,\n    \"lr\": 0.0002\n  },\n  \"data_loader_kwargs\": {\n    \"pin_memory\": true,\n    \"prefetch_factor\": 2,\n    \"num_workers\": 3\n  },\n  \"target\": 0.45,\n  \"ada_kimg\": 100,\n  \"training_set_kwargs\": {\n    \"class_name\": \"training.dataset.ImageFolderDataset\",\n    \"path\": \"/kaggle/input/milddementedrgb-pro256\",\n    \"use_labels\": false,\n    \"max_size\": 896,\n    \"xflip\": true,\n    \"resolution\": 256,\n    \"random_seed\": 0\n  },\n  \"num_gpus\": 1,\n  \"batch_size\": 16,\n  \"batch_gpu\": 16,\n  \"metrics\": [],\n  \"total_kimg\": 3700,\n  \"kimg_per_tick\": 4,\n  \"image_snapshot_ticks\": 5,\n  \"network_snapshot_ticks\": 5,\n  \"random_seed\": 0,\n  \"ema_kimg\": 5.0,\n  \"resume_pkl\": \"https://huggingface.co/zhendongw/diffusion-gan/resolve/main/checkpoints/diffusion-projectedgan-lsun-church.pkl\",\n  \"ema_rampup\": null,\n  \"restart_every\": 9999999,\n  \"loss_kwargs\": {\n    \"class_name\": \"training.loss.ProjectedGANLoss\"\n  },\n  \"D_kwargs\": {\n    \"class_name\": \"pg_modules.discriminator.ProjectedDiscriminator\",\n    \"diffaug\": true,\n    \"interp224\": false,\n    \"backbone_kwargs\": {\n      \"d_pos\": \"first\",\n      \"noise_sd\": 0.5,\n      \"cout\": 64,\n      \"expand\": true,\n      \"proj_type\": 2,\n      \"num_discs\": 4,\n      \"separable\": false,\n      \"cond\": false\n    }\n  },\n  \"run_dir\": \"training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100\"\n}\n\nOutput directory:    training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100\nNumber of GPUs:      1\nBatch size:          16 images\nTraining duration:   3700 kimg\nDataset path:        /kaggle/input/milddementedrgb-pro256\nDataset size:        896 images\nDataset resolution:  256\nDataset labels:      False\nDataset x-flips:     True\n\nCreating output directory...\nLaunching processes...\nLoading training set...\n/opt/conda/lib/python3.10/site-packages/torch/utils/data/sampler.py:65: UserWarning: `data_source` argument is not used and will be removed in 2.2.0.You may still have custom implementation that utilizes it.\n  warnings.warn(\"`data_source` argument is not used and will be removed in 2.2.0.\"\n\nNum images:  1792\nImage shape: [3, 256, 256]\nLabel shape: [0]\n\nConstructing networks...\nDownloading: \"https://github.com/rwightman/pytorch-image-models/releases/download/v0.1-weights/tf_efficientnet_lite0-0aa007d2.pth\" to /root/.cache/torch/hub/checkpoints/tf_efficientnet_lite0-0aa007d2.pth\nResuming from \"training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n\nGenerator              Parameters  Buffers  Output shape         Datatype\n---                    ---         ---      ---                  ---     \nmapping                -           -        [16, 1, 256]         float32 \nsynthesis.init.init    16785408    16385    [16, 2048, 4, 4]     float32 \nsynthesis.feat_8.0     -           -        [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.1     37748736    20480    [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.2     1           -        [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.3     4096        4097     [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.4     -           -        [16, 1024, 8, 8]     float32 \nsynthesis.feat_8.5     18874368    11264    [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.6     1           -        [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.7     4096        4097     [16, 2048, 8, 8]     float32 \nsynthesis.feat_8.8     -           -        [16, 1024, 8, 8]     float32 \nsynthesis.feat_16.0    -           -        [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.1    9437184     10240    [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.2    1           -        [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.3    2048        2049     [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.4    -           -        [16, 512, 16, 16]    float32 \nsynthesis.feat_16.5    4718592     5632     [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.6    1           -        [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.7    2048        2049     [16, 1024, 16, 16]   float32 \nsynthesis.feat_16.8    -           -        [16, 512, 16, 16]    float32 \nsynthesis.feat_32.0    -           -        [16, 512, 32, 32]    float32 \nsynthesis.feat_32.1    2359296     5120     [16, 512, 32, 32]    float32 \nsynthesis.feat_32.2    1           -        [16, 512, 32, 32]    float32 \nsynthesis.feat_32.3    1024        1025     [16, 512, 32, 32]    float32 \nsynthesis.feat_32.4    -           -        [16, 256, 32, 32]    float32 \nsynthesis.feat_32.5    1179648     2816     [16, 512, 32, 32]    float32 \nsynthesis.feat_32.6    1           -        [16, 512, 32, 32]    float32 \nsynthesis.feat_32.7    1024        1025     [16, 512, 32, 32]    float32 \nsynthesis.feat_32.8    -           -        [16, 256, 32, 32]    float32 \nsynthesis.feat_64.0    -           -        [16, 256, 64, 64]    float32 \nsynthesis.feat_64.1    1179648     2816     [16, 512, 64, 64]    float32 \nsynthesis.feat_64.2    1           -        [16, 512, 64, 64]    float32 \nsynthesis.feat_64.3    1024        1025     [16, 512, 64, 64]    float32 \nsynthesis.feat_64.4    -           -        [16, 256, 64, 64]    float32 \nsynthesis.feat_64.5    1179648     2816     [16, 512, 64, 64]    float32 \nsynthesis.feat_64.6    1           -        [16, 512, 64, 64]    float32 \nsynthesis.feat_64.7    1024        1025     [16, 512, 64, 64]    float32 \nsynthesis.feat_64.8    -           -        [16, 256, 64, 64]    float32 \nsynthesis.se_64.main   8454144     33536    [16, 256, 1, 1]      float32 \nsynthesis.se_64        -           -        [16, 256, 64, 64]    float32 \nsynthesis.feat_128.0   -           -        [16, 256, 128, 128]  float32 \nsynthesis.feat_128.1   589824      2560     [16, 256, 128, 128]  float32 \nsynthesis.feat_128.2   1           -        [16, 256, 128, 128]  float32 \nsynthesis.feat_128.3   512         513      [16, 256, 128, 128]  float32 \nsynthesis.feat_128.4   -           -        [16, 128, 128, 128]  float32 \nsynthesis.feat_128.5   294912      1408     [16, 256, 128, 128]  float32 \nsynthesis.feat_128.6   1           -        [16, 256, 128, 128]  float32 \nsynthesis.feat_128.7   512         513      [16, 256, 128, 128]  float32 \nsynthesis.feat_128.8   -           -        [16, 128, 128, 128]  float32 \nsynthesis.se_128.main  2113536     16768    [16, 128, 1, 1]      float32 \nsynthesis.se_128       -           -        [16, 128, 128, 128]  float32 \nsynthesis.feat_256.0   -           -        [16, 128, 256, 256]  float32 \nsynthesis.feat_256.1   147456      1280     [16, 128, 256, 256]  float32 \nsynthesis.feat_256.2   1           -        [16, 128, 256, 256]  float32 \nsynthesis.feat_256.3   256         257      [16, 128, 256, 256]  float32 \nsynthesis.feat_256.4   -           -        [16, 64, 256, 256]   float32 \nsynthesis.feat_256.5   73728       704      [16, 128, 256, 256]  float32 \nsynthesis.feat_256.6   1           -        [16, 128, 256, 256]  float32 \nsynthesis.feat_256.7   256         257      [16, 128, 256, 256]  float32 \nsynthesis.feat_256.8   -           -        [16, 64, 256, 256]   float32 \nsynthesis.se_256.main  528384      8384     [16, 64, 1, 1]       float32 \nsynthesis.se_256       -           -        [16, 64, 256, 256]   float32 \nsynthesis.to_big       1731        579      [16, 3, 256, 256]    float32 \n---                    ---         ---      ---                  ---     \nTotal                  105684175   160720   -                    -       \n\n/opt/conda/lib/python3.10/site-packages/torch/functional.py:513: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at /usr/local/src/pytorch/aten/src/ATen/native/TensorShape.cpp:3609.)\n  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n\nProjectedDiscriminator                                               Parameters  Buffers  Output shape        Datatype\n---                                                                  ---         ---      ---                 ---     \nfeature_network.pretrained.layer0.0                                  864         -        [16, 32, 128, 128]  float32 \nfeature_network.pretrained.layer0.1                                  64          65       [16, 32, 128, 128]  float32 \nfeature_network.pretrained.layer0.3                                  896         98       [16, 16, 128, 128]  float32 \nfeature_network.pretrained.layer0.4                                  13968       1062     [16, 24, 64, 64]    float32 \nfeature_network.pretrained.layer1.0                                  39712       1702     [16, 40, 32, 32]    float32 \nfeature_network.pretrained.layer2.0                                  198480      5289     [16, 80, 16, 16]    float32 \nfeature_network.pretrained.layer2.1                                  446784      7977     [16, 112, 16, 16]   float32 \nfeature_network.pretrained.layer3.0                                  1652640     18060    [16, 192, 8, 8]     float32 \nfeature_network.pretrained.layer3.1                                  605440      5251     [16, 320, 8, 8]     float32 \nfeature_network.diffusion                                            -           -        [16, 24, 64, 64]    float32 \nfeature_network.diffusion                                            -           -        [16, 40, 32, 32]    float32 \nfeature_network.diffusion                                            -           -        [16, 112, 16, 16]   float32 \nfeature_network.diffusion                                            -           -        [16, 320, 8, 8]     float32 \nfeature_network.scratch.layer0_ccm                                   1600        -        [16, 64, 64, 64]    float32 \nfeature_network.scratch.layer1_ccm                                   5248        -        [16, 128, 32, 32]   float32 \nfeature_network.scratch.layer2_ccm                                   28928       -        [16, 256, 16, 16]   float32 \nfeature_network.scratch.layer3_ccm                                   164352      -        [16, 512, 8, 8]     float32 \nfeature_network.scratch.layer3_csm.out_conv                          131328      -        [16, 256, 16, 16]   float32 \nfeature_network.scratch.layer2_csm.skip_add.activation_post_process  -           -        [16, 256, 16, 16]   float32 \nfeature_network.scratch.layer2_csm.out_conv                          32896       -        [16, 128, 32, 32]   float32 \nfeature_network.scratch.layer1_csm.skip_add.activation_post_process  -           -        [16, 128, 32, 32]   float32 \nfeature_network.scratch.layer1_csm.out_conv                          8256        -        [16, 64, 64, 64]    float32 \nfeature_network.scratch.layer0_csm.skip_add.activation_post_process  -           -        [16, 64, 64, 64]    float32 \nfeature_network.scratch.layer0_csm.out_conv                          4160        -        [16, 64, 128, 128]  float32 \ndiscriminator.mini_discs.0.main                                      2829120     19269    [16, 1, 5, 5]       float32 \ndiscriminator.mini_discs.1.main                                      2763392     18052    [16, 1, 5, 5]       float32 \ndiscriminator.mini_discs.2.main                                      2631936     16643    [16, 1, 5, 5]       float32 \ndiscriminator.mini_discs.3.main                                      2106880     13826    [16, 1, 5, 5]       float32 \ndiscriminator                                                        -           -        [16, 100]           float32 \n---                                                                  ---         ---      ---                 ---     \nTotal                                                                13666944    107294   -                   -       \n\nSetting up augmentation...\nDistributing across 1 GPUs...\nSetting up training phases...\nExporting sample images...\nInitializing logs...\nTraining for 3700 kimg...\n\ntick 858   kimg 3664.0   time 8m 26s       sec/tick 457.9   sec/kimg 114.47  maintenance 47.9   cpumem 2.74   gpumem 12.54  reserved 13.52  augment 1.000 T 500.0\ntick 859   kimg 3668.0   time 15m 36s      sec/tick 430.5   sec/kimg 107.62  maintenance 0.0    cpumem 2.74   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 860   kimg 3672.0   time 22m 47s      sec/tick 430.9   sec/kimg 107.72  maintenance 0.0    cpumem 2.74   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 861   kimg 3676.0   time 30m 20s      sec/tick 431.6   sec/kimg 107.89  maintenance 21.7   cpumem 2.72   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 862   kimg 3680.0   time 37m 31s      sec/tick 430.4   sec/kimg 107.61  maintenance 0.0    cpumem 2.72   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 863   kimg 3684.0   time 44m 42s      sec/tick 430.9   sec/kimg 107.73  maintenance 0.0    cpumem 2.72   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 864   kimg 3688.0   time 51m 52s      sec/tick 430.0   sec/kimg 107.50  maintenance 0.0    cpumem 2.72   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 865   kimg 3692.0   time 59m 01s      sec/tick 429.6   sec/kimg 107.41  maintenance 0.0    cpumem 2.72   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 866   kimg 3696.0   time 1h 06m 33s   sec/tick 430.3   sec/kimg 107.59  maintenance 21.4   cpumem 2.79   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\ntick 867   kimg 3700.0   time 1h 13m 44s   sec/tick 430.5   sec/kimg 107.62  maintenance 0.0    cpumem 2.79   gpumem 11.21  reserved 13.52  augment 1.000 T 500.0\n\nExiting...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py  --metrics=fid50k_full --data='/kaggle/input/milddementedrgb-pro256' --mirror=1   --network='/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-12T11:39:59.868374Z",
          "iopub.execute_input": "2025-01-12T11:39:59.868811Z",
          "iopub.status.idle": "2025-01-12T12:07:39.090824Z",
          "shell.execute_reply.started": "2025-01-12T11:39:59.868763Z",
          "shell.execute_reply": "2025-01-12T12:07:39.089608Z"
        },
        "id": "JXdmqFAz3cKq",
        "outputId": "24ca8fb7-3071-46a9-fba8-0e8c76bf7b6f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading network from \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nDataset options:\n{\n  \"class_name\": \"training.dataset.ImageFolderDataset\",\n  \"path\": \"/kaggle/input/milddementedrgb-pro256\",\n  \"resolution\": 256,\n  \"use_labels\": false,\n  \"xflip\": true\n}\nLaunching processes...\n\nGenerator              Parameters  Buffers  Output shape        Datatype\n---                    ---         ---      ---                 ---     \nmapping                -           -        [1, 1, 256]         float32 \nsynthesis.init.init    16785408    16385    [1, 2048, 4, 4]     float32 \nsynthesis.feat_8.0     -           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.1     37748736    20480    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.2     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.3     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.4     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_8.5     18874368    11264    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.6     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.7     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.8     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_16.0    -           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.1    9437184     10240    [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.2    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.3    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.4    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_16.5    4718592     5632     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.6    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.7    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.8    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_32.0    -           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.1    2359296     5120     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.2    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.3    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.4    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_32.5    1179648     2816     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.6    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.7    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.8    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_64.0    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.1    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.2    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.3    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.4    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.5    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.6    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.7    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.8    -           -        [1, 256, 64, 64]    float32 \nsynthesis.se_64.main   8454144     33536    [1, 256, 1, 1]      float32 \nsynthesis.se_64        -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_128.0   -           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.1   589824      2560     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.2   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.3   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.4   -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_128.5   294912      1408     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.6   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.7   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.8   -           -        [1, 128, 128, 128]  float32 \nsynthesis.se_128.main  2113536     16768    [1, 128, 1, 1]      float32 \nsynthesis.se_128       -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_256.0   -           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.1   147456      1280     [1, 128, 256, 256]  float32 \nsynthesis.feat_256.2   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.3   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.4   -           -        [1, 64, 256, 256]   float32 \nsynthesis.feat_256.5   73728       704      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.6   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.7   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.8   -           -        [1, 64, 256, 256]   float32 \nsynthesis.se_256.main  528384      8384     [1, 64, 1, 1]       float32 \nsynthesis.se_256       -           -        [1, 64, 256, 256]   float32 \nsynthesis.to_big       1731        579      [1, 3, 256, 256]    float32 \n---                    ---         ---      ---                 ---     \nTotal                  105684175   160720   -                   -       \n\nCalculating fid50k_full...\nDownloading https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/inception-2015-12-05.pkl ... done\n/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(io.BytesIO(b))\ngenerator features  items 1024    time 32s          ms/item 30.84\ngenerator features  items 2048    time 1m 04s       ms/item 31.19\ngenerator features  items 3072    time 1m 38s       ms/item 33.57\ngenerator features  items 4096    time 2m 11s       ms/item 32.55\ngenerator features  items 5120    time 2m 45s       ms/item 32.67\ngenerator features  items 6144    time 3m 18s       ms/item 32.94\ngenerator features  items 7168    time 3m 52s       ms/item 32.63\ngenerator features  items 8192    time 4m 25s       ms/item 32.77\ngenerator features  items 9216    time 4m 59s       ms/item 32.80\ngenerator features  items 10240   time 5m 33s       ms/item 33.04\ngenerator features  items 11264   time 6m 07s       ms/item 32.92\ngenerator features  items 12288   time 6m 40s       ms/item 32.85\ngenerator features  items 13312   time 7m 14s       ms/item 32.92\ngenerator features  items 14336   time 7m 48s       ms/item 32.90\ngenerator features  items 15360   time 8m 21s       ms/item 32.80\ngenerator features  items 16384   time 8m 55s       ms/item 32.81\ngenerator features  items 17408   time 9m 28s       ms/item 32.82\ngenerator features  items 18432   time 10m 02s      ms/item 32.86\ngenerator features  items 19456   time 10m 36s      ms/item 32.87\ngenerator features  items 20480   time 11m 09s      ms/item 32.81\ngenerator features  items 21504   time 11m 43s      ms/item 32.86\ngenerator features  items 22528   time 12m 17s      ms/item 32.87\ngenerator features  items 23552   time 12m 50s      ms/item 32.90\ngenerator features  items 24576   time 13m 24s      ms/item 32.98\ngenerator features  items 25600   time 13m 58s      ms/item 32.84\ngenerator features  items 26624   time 14m 31s      ms/item 32.92\ngenerator features  items 27648   time 15m 05s      ms/item 32.88\ngenerator features  items 28672   time 15m 39s      ms/item 32.85\ngenerator features  items 29696   time 16m 12s      ms/item 32.90\ngenerator features  items 30720   time 16m 46s      ms/item 32.92\ngenerator features  items 31744   time 17m 20s      ms/item 32.86\ngenerator features  items 32768   time 17m 53s      ms/item 32.97\ngenerator features  items 33792   time 18m 27s      ms/item 32.88\ngenerator features  items 34816   time 19m 01s      ms/item 32.92\ngenerator features  items 35840   time 19m 34s      ms/item 32.86\ngenerator features  items 36864   time 20m 08s      ms/item 32.87\ngenerator features  items 37888   time 20m 42s      ms/item 32.85\ngenerator features  items 38912   time 21m 15s      ms/item 32.84\ngenerator features  items 39936   time 21m 49s      ms/item 32.84\ngenerator features  items 40960   time 22m 23s      ms/item 32.78\ngenerator features  items 41984   time 22m 56s      ms/item 32.74\ngenerator features  items 43008   time 23m 30s      ms/item 32.81\ngenerator features  items 44032   time 24m 03s      ms/item 32.83\ngenerator features  items 45056   time 24m 37s      ms/item 32.84\ngenerator features  items 46080   time 25m 11s      ms/item 32.88\ngenerator features  items 47104   time 25m 44s      ms/item 32.87\ngenerator features  items 48128   time 26m 18s      ms/item 32.77\ngenerator features  items 49152   time 26m 51s      ms/item 32.81\ngenerator features  items 50000   time 27m 21s      ms/item 34.57\n{\"results\": {\"fid50k_full\": 12.345829551505137}, \"metric\": \"fid50k_full\", \"total_time\": 1648.4948496818542, \"total_time_str\": \"27m 28s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot.pkl\", \"timestamp\": 1736683657.8833888}\n\nExiting...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py  --metrics=fid50k --data='/kaggle/input/milddementedrgb-pro256' --mirror=1   --network='/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-12T12:13:23.546181Z",
          "iopub.execute_input": "2025-01-12T12:13:23.54701Z",
          "iopub.status.idle": "2025-01-12T12:40:58.911326Z",
          "shell.execute_reply.started": "2025-01-12T12:13:23.546969Z",
          "shell.execute_reply": "2025-01-12T12:40:58.910219Z"
        },
        "id": "ex3hUIyv3cKr",
        "outputId": "1a25db6a-a9b8-49c2-e00b-3aa3d4187b53"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading network from \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nDataset options:\n{\n  \"class_name\": \"training.dataset.ImageFolderDataset\",\n  \"path\": \"/kaggle/input/milddementedrgb-pro256\",\n  \"resolution\": 256,\n  \"use_labels\": false,\n  \"xflip\": true\n}\nLaunching processes...\n\nGenerator              Parameters  Buffers  Output shape        Datatype\n---                    ---         ---      ---                 ---     \nmapping                -           -        [1, 1, 256]         float32 \nsynthesis.init.init    16785408    16385    [1, 2048, 4, 4]     float32 \nsynthesis.feat_8.0     -           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.1     37748736    20480    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.2     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.3     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.4     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_8.5     18874368    11264    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.6     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.7     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.8     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_16.0    -           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.1    9437184     10240    [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.2    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.3    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.4    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_16.5    4718592     5632     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.6    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.7    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.8    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_32.0    -           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.1    2359296     5120     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.2    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.3    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.4    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_32.5    1179648     2816     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.6    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.7    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.8    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_64.0    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.1    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.2    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.3    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.4    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.5    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.6    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.7    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.8    -           -        [1, 256, 64, 64]    float32 \nsynthesis.se_64.main   8454144     33536    [1, 256, 1, 1]      float32 \nsynthesis.se_64        -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_128.0   -           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.1   589824      2560     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.2   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.3   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.4   -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_128.5   294912      1408     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.6   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.7   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.8   -           -        [1, 128, 128, 128]  float32 \nsynthesis.se_128.main  2113536     16768    [1, 128, 1, 1]      float32 \nsynthesis.se_128       -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_256.0   -           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.1   147456      1280     [1, 128, 256, 256]  float32 \nsynthesis.feat_256.2   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.3   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.4   -           -        [1, 64, 256, 256]   float32 \nsynthesis.feat_256.5   73728       704      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.6   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.7   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.8   -           -        [1, 64, 256, 256]   float32 \nsynthesis.se_256.main  528384      8384     [1, 64, 1, 1]       float32 \nsynthesis.se_256       -           -        [1, 64, 256, 256]   float32 \nsynthesis.to_big       1731        579      [1, 3, 256, 256]    float32 \n---                    ---         ---      ---                 ---     \nTotal                  105684175   160720   -                   -       \n\nCalculating fid50k...\n/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(io.BytesIO(b))\ngenerator features  items 1024    time 31s          ms/item 29.97\ngenerator features  items 2048    time 1m 02s       ms/item 31.05\ngenerator features  items 3072    time 1m 37s       ms/item 33.55\ngenerator features  items 4096    time 2m 10s       ms/item 32.44\ngenerator features  items 5120    time 2m 44s       ms/item 32.74\ngenerator features  items 6144    time 3m 17s       ms/item 32.89\ngenerator features  items 7168    time 3m 51s       ms/item 32.68\ngenerator features  items 8192    time 4m 24s       ms/item 32.80\ngenerator features  items 9216    time 4m 58s       ms/item 32.91\ngenerator features  items 10240   time 5m 32s       ms/item 32.78\ngenerator features  items 11264   time 6m 05s       ms/item 32.79\ngenerator features  items 12288   time 6m 39s       ms/item 32.79\ngenerator features  items 13312   time 7m 12s       ms/item 32.76\ngenerator features  items 14336   time 7m 46s       ms/item 32.75\ngenerator features  items 15360   time 8m 19s       ms/item 32.79\ngenerator features  items 16384   time 8m 53s       ms/item 32.78\ngenerator features  items 17408   time 9m 27s       ms/item 32.79\ngenerator features  items 18432   time 10m 00s      ms/item 32.82\ngenerator features  items 19456   time 10m 34s      ms/item 32.76\ngenerator features  items 20480   time 11m 07s      ms/item 32.83\ngenerator features  items 21504   time 11m 41s      ms/item 32.77\ngenerator features  items 22528   time 12m 14s      ms/item 32.76\ngenerator features  items 23552   time 12m 48s      ms/item 32.80\ngenerator features  items 24576   time 13m 22s      ms/item 32.79\ngenerator features  items 25600   time 13m 55s      ms/item 32.74\ngenerator features  items 26624   time 14m 29s      ms/item 32.76\ngenerator features  items 27648   time 15m 02s      ms/item 32.80\ngenerator features  items 28672   time 15m 36s      ms/item 32.79\ngenerator features  items 29696   time 16m 09s      ms/item 32.78\ngenerator features  items 30720   time 16m 43s      ms/item 32.82\ngenerator features  items 31744   time 17m 17s      ms/item 32.80\ngenerator features  items 32768   time 17m 50s      ms/item 32.78\ngenerator features  items 33792   time 18m 24s      ms/item 32.79\ngenerator features  items 34816   time 18m 57s      ms/item 32.89\ngenerator features  items 35840   time 19m 31s      ms/item 32.85\ngenerator features  items 36864   time 20m 05s      ms/item 32.77\ngenerator features  items 37888   time 20m 38s      ms/item 32.86\ngenerator features  items 38912   time 21m 12s      ms/item 32.85\ngenerator features  items 39936   time 21m 45s      ms/item 32.80\ngenerator features  items 40960   time 22m 19s      ms/item 32.77\ngenerator features  items 41984   time 22m 53s      ms/item 32.68\ngenerator features  items 43008   time 23m 26s      ms/item 32.71\ngenerator features  items 44032   time 23m 59s      ms/item 32.70\ngenerator features  items 45056   time 24m 33s      ms/item 32.77\ngenerator features  items 46080   time 25m 07s      ms/item 32.78\ngenerator features  items 47104   time 25m 40s      ms/item 32.77\ngenerator features  items 48128   time 26m 14s      ms/item 32.84\ngenerator features  items 49152   time 26m 47s      ms/item 32.76\ngenerator features  items 50000   time 27m 17s      ms/item 34.58\n{\"results\": {\"fid50k\": 10.71461681695804}, \"metric\": \"fid50k\", \"total_time\": 1645.052321434021, \"total_time_str\": \"27m 25s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot.pkl\", \"timestamp\": 1736685657.757448}\n\nExiting...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py  --metrics=pr50k3_full   --data='/kaggle/input/milddementedrgb-pro256' --mirror=1   --network='/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-11T19:34:54.533466Z",
          "iopub.execute_input": "2025-01-11T19:34:54.534408Z",
          "iopub.status.idle": "2025-01-11T20:03:29.980719Z",
          "shell.execute_reply.started": "2025-01-11T19:34:54.534373Z",
          "shell.execute_reply": "2025-01-11T20:03:29.979186Z"
        },
        "id": "JZJhbk643cKs",
        "outputId": "a1bd9643-9a46-4df4-a4bc-ab896bf57710"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading network from \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nDataset options:\n{\n  \"class_name\": \"training.dataset.ImageFolderDataset\",\n  \"path\": \"/kaggle/input/milddementedrgb-pro256\",\n  \"resolution\": 256,\n  \"use_labels\": false,\n  \"xflip\": true\n}\nLaunching processes...\n\nGenerator              Parameters  Buffers  Output shape        Datatype\n---                    ---         ---      ---                 ---     \nmapping                -           -        [1, 1, 256]         float32 \nsynthesis.init.init    16785408    16385    [1, 2048, 4, 4]     float32 \nsynthesis.feat_8.0     -           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.1     37748736    20480    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.2     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.3     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.4     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_8.5     18874368    11264    [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.6     1           -        [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.7     4096        4097     [1, 2048, 8, 8]     float32 \nsynthesis.feat_8.8     -           -        [1, 1024, 8, 8]     float32 \nsynthesis.feat_16.0    -           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.1    9437184     10240    [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.2    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.3    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.4    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_16.5    4718592     5632     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.6    1           -        [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.7    2048        2049     [1, 1024, 16, 16]   float32 \nsynthesis.feat_16.8    -           -        [1, 512, 16, 16]    float32 \nsynthesis.feat_32.0    -           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.1    2359296     5120     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.2    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.3    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.4    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_32.5    1179648     2816     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.6    1           -        [1, 512, 32, 32]    float32 \nsynthesis.feat_32.7    1024        1025     [1, 512, 32, 32]    float32 \nsynthesis.feat_32.8    -           -        [1, 256, 32, 32]    float32 \nsynthesis.feat_64.0    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.1    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.2    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.3    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.4    -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_64.5    1179648     2816     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.6    1           -        [1, 512, 64, 64]    float32 \nsynthesis.feat_64.7    1024        1025     [1, 512, 64, 64]    float32 \nsynthesis.feat_64.8    -           -        [1, 256, 64, 64]    float32 \nsynthesis.se_64.main   8454144     33536    [1, 256, 1, 1]      float32 \nsynthesis.se_64        -           -        [1, 256, 64, 64]    float32 \nsynthesis.feat_128.0   -           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.1   589824      2560     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.2   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.3   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.4   -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_128.5   294912      1408     [1, 256, 128, 128]  float32 \nsynthesis.feat_128.6   1           -        [1, 256, 128, 128]  float32 \nsynthesis.feat_128.7   512         513      [1, 256, 128, 128]  float32 \nsynthesis.feat_128.8   -           -        [1, 128, 128, 128]  float32 \nsynthesis.se_128.main  2113536     16768    [1, 128, 1, 1]      float32 \nsynthesis.se_128       -           -        [1, 128, 128, 128]  float32 \nsynthesis.feat_256.0   -           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.1   147456      1280     [1, 128, 256, 256]  float32 \nsynthesis.feat_256.2   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.3   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.4   -           -        [1, 64, 256, 256]   float32 \nsynthesis.feat_256.5   73728       704      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.6   1           -        [1, 128, 256, 256]  float32 \nsynthesis.feat_256.7   256         257      [1, 128, 256, 256]  float32 \nsynthesis.feat_256.8   -           -        [1, 64, 256, 256]   float32 \nsynthesis.se_256.main  528384      8384     [1, 64, 1, 1]       float32 \nsynthesis.se_256       -           -        [1, 64, 256, 256]   float32 \nsynthesis.to_big       1731        579      [1, 3, 256, 256]    float32 \n---                    ---         ---      ---                 ---     \nTotal                  105684175   160720   -                   -       \n\nCalculating pr50k3_full...\nCalculating the stats for this dataset the first time\n\nSaving them to ./dnnlib/gan-metrics/milddementedrgb-pro256-vgg16-7864f8b37cf23d7202093c98a1053065.pkl\nDownloading https://api.ngc.nvidia.com/v2/models/nvidia/research/stylegan3/versions/1/files/metrics/vgg16.pkl ... done\n/opt/conda/lib/python3.10/site-packages/torch/storage.py:414: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return torch.load(io.BytesIO(b))\n 93%|#########2| 13/14 [00:08<00:00,  3.30it/s]dataset features    items 896     time 32s          ms/item 35.75\n100%|##########| 14/14 [00:09<00:00,  1.48it/s]\ngenerator features  items 1024    time 29s          ms/item 28.55\ngenerator features  items 2048    time 1m 00s       ms/item 29.78\ngenerator features  items 3072    time 1m 31s       ms/item 30.48\ngenerator features  items 4096    time 2m 04s       ms/item 32.07\ngenerator features  items 5120    time 2m 38s       ms/item 33.07\ngenerator features  items 6144    time 3m 11s       ms/item 32.40\ngenerator features  items 7168    time 3m 44s       ms/item 32.60\ngenerator features  items 8192    time 4m 18s       ms/item 32.84\ngenerator features  items 9216    time 4m 51s       ms/item 32.73\ngenerator features  items 10240   time 5m 25s       ms/item 32.79\ngenerator features  items 11264   time 5m 58s       ms/item 32.76\ngenerator features  items 12288   time 6m 32s       ms/item 32.83\ngenerator features  items 13312   time 7m 06s       ms/item 32.78\ngenerator features  items 14336   time 7m 39s       ms/item 32.78\ngenerator features  items 15360   time 8m 13s       ms/item 32.83\ngenerator features  items 16384   time 8m 46s       ms/item 32.77\ngenerator features  items 17408   time 9m 20s       ms/item 32.78\ngenerator features  items 18432   time 9m 54s       ms/item 32.78\ngenerator features  items 19456   time 10m 27s      ms/item 32.79\ngenerator features  items 20480   time 11m 01s      ms/item 32.81\ngenerator features  items 21504   time 11m 34s      ms/item 32.84\ngenerator features  items 22528   time 12m 08s      ms/item 32.83\ngenerator features  items 23552   time 12m 42s      ms/item 32.79\ngenerator features  items 24576   time 13m 15s      ms/item 32.76\ngenerator features  items 25600   time 13m 49s      ms/item 32.72\ngenerator features  items 26624   time 14m 22s      ms/item 32.65\ngenerator features  items 27648   time 14m 55s      ms/item 32.63\ngenerator features  items 28672   time 15m 29s      ms/item 32.62\ngenerator features  items 29696   time 16m 02s      ms/item 32.60\ngenerator features  items 30720   time 16m 36s      ms/item 32.63\ngenerator features  items 31744   time 17m 09s      ms/item 32.59\ngenerator features  items 32768   time 17m 42s      ms/item 32.59\ngenerator features  items 33792   time 18m 16s      ms/item 32.56\ngenerator features  items 34816   time 18m 49s      ms/item 32.59\ngenerator features  items 35840   time 19m 22s      ms/item 32.57\ngenerator features  items 36864   time 19m 56s      ms/item 32.56\ngenerator features  items 37888   time 20m 29s      ms/item 32.58\ngenerator features  items 38912   time 21m 02s      ms/item 32.53\ngenerator features  items 39936   time 21m 36s      ms/item 32.60\ngenerator features  items 40960   time 22m 09s      ms/item 32.61\ngenerator features  items 41984   time 22m 43s      ms/item 32.62\ngenerator features  items 43008   time 23m 16s      ms/item 32.62\ngenerator features  items 44032   time 23m 49s      ms/item 32.67\ngenerator features  items 45056   time 24m 23s      ms/item 32.69\ngenerator features  items 46080   time 24m 56s      ms/item 32.70\ngenerator features  items 47104   time 25m 30s      ms/item 32.68\ngenerator features  items 48128   time 26m 03s      ms/item 32.75\ngenerator features  items 49152   time 26m 37s      ms/item 32.77\ngenerator features  items 50000   time 27m 06s      ms/item 34.61\n{\"results\": {\"pr50k3_full_precision\": 0.6385800242424011, \"pr50k3_full_recall\": 0.0725446417927742}, \"metric\": \"pr50k3_full\", \"total_time\": 1705.0517673492432, \"total_time_str\": \"28m 25s\", \"num_gpus\": 1, \"snapshot_pkl\": \"network-snapshot.pkl\", \"timestamp\": 1736625808.6923943}\n\nExiting...\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "code",
      "source": [
        "!python /kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py  --metrics=kid50k_full   --data='/kaggle/input/milddementedrgb-pro256' --mirror=1   --network='/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl'"
      ],
      "metadata": {
        "trusted": true,
        "execution": {
          "iopub.status.busy": "2025-01-18T19:15:32.271975Z",
          "iopub.execute_input": "2025-01-18T19:15:32.272831Z",
          "iopub.status.idle": "2025-01-18T19:15:38.154193Z",
          "shell.execute_reply.started": "2025-01-18T19:15:32.272785Z",
          "shell.execute_reply": "2025-01-18T19:15:38.153308Z"
        },
        "collapsed": true,
        "jupyter": {
          "outputs_hidden": true
        },
        "id": "riqv9WXB3cKt",
        "outputId": "73fbfff1-6440-4e1f-e28b-08668dea778f"
      },
      "outputs": [
        {
          "name": "stdout",
          "text": "Loading network from \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/training-runs/00000-fastgan-milddementedrgb-pro256-gpus1-batch16-d_pos-first-noise_sd-0.5-target0.45-ada_kimg100/network-snapshot.pkl\"...\n/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py:71: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n  return lambda b: torch.load(io.BytesIO(b), map_location='cpu')\nTraceback (most recent call last):\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py\", line 186, in <module>\n    calc_metrics() # pylint: disable=no-value-for-parameter\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1157, in __call__\n    return self.main(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1078, in main\n    rv = self.invoke(ctx)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 1434, in invoke\n    return ctx.invoke(self.callback, **ctx.params)\n  File \"/opt/conda/lib/python3.10/site-packages/click/core.py\", line 783, in invoke\n    return __callback(*args, **kwargs)\n  File \"/opt/conda/lib/python3.10/site-packages/click/decorators.py\", line 33, in new_func\n    return f(get_current_context(), *args, **kwargs)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/calc_metrics.py\", line 144, in calc_metrics\n    network_dict = legacy.load_network_pkl(f)\n  File \"/kaggle/working/Diffusion-GAN/diffusion-projected-gan/legacy.py\", line 24, in load_network_pkl\n    data = _LegacyUnpickler(f).load()\n_pickle.UnpicklingError: pickle data was truncated\n",
          "output_type": "stream"
        }
      ],
      "execution_count": null
    }
  ]
}